# 关于人格稳定性（收敛性）的分析

本文档阐述了针对大语言模型（LLM）为单个Persona生成人格时其稳定性分析的设计与实现。

## 1. 分析目标

核心目标是判断一个LLM在接收到同一个Persona的描述并被反复提问时，是否能产出一个稳定且一致的人格画像。如果实验结果是稳定的，这表明LLM为该Persona形成了一个连贯的内部表征。我们将这种特性称为稳定性或收敛性。

本分析的数据集基于对单个Persona进行300次人格测试（例如IPIP-NEO），每次测试结果都是一个代表大五人格特质的5维向量。

## 2. 方法论与实现

我们采用多种方法来可视化和分析这300个向量在高维空间中的分布。

### 方法一：欧几里得距离分布

-   **核心思想:** 此方法将5维信息压缩到一个单一维度上，即每个点与“平均人格”的距离。它计算每一个向量到所有向量算术平均中心的直线距离（欧几里得距离）。
-   **代码实现:** `asociety/personality/personality_distribute.py` 脚本实现了此分析。
-   **可视化:** 生成一个直方图（柱状图），展示这些距离值的概率分布。
-   **结果解读:** 如果分布紧密地聚集在一个较小的距离值周围，说明稳定性高。

### 方法二：马氏距离分布

-   **核心思想:** 这是一种更高级的统计距离度量。它不再是简单的直线距离，而是在计算一个点到数据簇中心的距离时，同时考虑了每个特质的方差以及特质之间的相关性。它实质上衡量的是一个点距离该分布的均值有多少个标准差。
-   **代码实现:** `asociety/personality/personality_mahalanobis.py` 脚本实现了此分析。
-   **可视化:** 生成马氏距离的直方图。
-   **结果解读:** 这是识别多维数据集中异常值的黄金标准。一个紧密的分布表明绝大多数数据点都是统计上的“典型”样本，与整个群体的特征保持一致，这代表了高度的稳定性。

### 方法三：主成分分析 (PCA)

-   **核心思想:** PCA是一种降维技术，它能提供一个关于数据结构更全面的视图。它不是将信息压缩成单一的距离，而是将5维数据投影到一个能捕捉最大数据方差的2D平面上。这让我们能直观地观察数据云的“形状”。
-   **代码实现:** `asociety/personality/personality_pca.py` 脚本实现了此分析。
-   **可视化:** 生成一个2D散点图，其中每个点代表300次测试中的一次结果。
-   **结果解读:** 如果在散点图上观察到一个单一、密集的、大致为圆形的点簇，这是稳定性和收敛性的有力证据。
