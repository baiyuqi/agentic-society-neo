# Analysis of Personality Profile Identifiability

This document outlines the design and implementation for analyzing the identifiability of personality profiles generated by a Large Language Model (LLM) from two different persona descriptions.

## 1. Objective

The primary goal is to determine if an LLM can generate distinct and statistically distinguishable personality profiles from two different persona descriptions. If the resulting profiles are distinguishable, it demonstrates that the LLM is not generating random noise but is creating unique character traits based on the input. We refer to this as identifiability.

The analysis is based on two datasets, each containing 300 personality test results generated from a different source persona.

## 2. Methodology & Implementation

We use two primary approaches: a supervised comparison and a more advanced unsupervised validation.

### Method 1: Supervised Comparison

This approach uses traditional statistical and visual methods where we know in advance which data point belongs to which source persona.

-   **Implementation:** `asociety/personality/compare_personalities.py`
-   **Univariate Analysis (Trait-by-Trait):**
    -   **Visualization (Violin Plots):** For each of the five traits, we generate side-by-side violin plots to visually compare the distribution shape, median, and range of the data for each profile.
    -   **Statistical Test (T-test):** An independent samples t-test is performed on each trait to determine if the mean scores are statistically different.
-   **Multivariate Analysis (Holistic Profile):**
    -   **Visualization (PCA):** All 600 data points are projected onto a 2D scatter plot, with each profile's points colored differently, to visually assess the separation between the two data clouds.
    -   **Statistical Test (Mahalanobis Distance):** We calculate the Mahalanobis distance between the centroids of the two groups to get a single, robust number quantifying the separation between the two profiles.

### Method 2: Unsupervised Clustering (Objective Validation)

This is a more powerful approach that provides the strongest evidence of identifiability. Instead of comparing the two known groups, we mix all the data together and challenge a machine learning algorithm to rediscover the original groups without any prior knowledge.

-   **Implementation:** `asociety/personality/personality_clustering.py`
-   **Concept:** We use the **K-Means clustering algorithm** with K=2 to partition the 600 mixed data points into two clusters based on their natural structure.
-   **Quantitative Validation (Adjusted Rand Index - ARI):**
    -   We compare the clusters found by the algorithm to the true source profile labels using the ARI. This score measures the similarity between the two groupings, correcting for chance.
    -   An ARI of **1.0** signifies a perfect match (the algorithm perfectly rediscovered the two profiles), while a score near **0.0** indicates the clustering was no better than random. This is our primary metric for identifiability.
-   **Visual Validation (PCA Plot with Mixed Markers):**
    -   We generate a 2D PCA scatter plot where the **color** of each point represents the cluster assigned by the algorithm, and the **shape** of the point represents its true source profile.
    -   If the profiles are identifiable, we expect to see a near-perfect alignment of shape and color (e.g., all circles are blue, and all 'x's are green). This provides compelling visual proof that the algorithm successfully separated the profiles.
